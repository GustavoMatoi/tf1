// Captura o elemento de v√≠deo da p√°gina HTML
const video = document.getElementById("video");

// Captura o elemento canvas onde os pontos da m√£o ser√£o desenhados
const canvas = document.getElementById("canvas");

// Obt√©m o contexto 2D do canvas, usado para desenhar na tela
const ctx = canvas.getContext("2d");

// Define as pontas dos dedos (√≠ndices dos pontos no modelo) e a cor para cada um
const fingertipPoints = {
  4: "red",        // Polegar
  8: "orange",     // Indicador
  12: "yellow",    // M√©dio
  16: "deepskyblue", // Anelar
  20: "violet",    // Mindinho
};

// Define os pares de dedos que devem ser comparados para medir dist√¢ncia
const proximityPairs = [
  [4, 8],   // Polegar e indicador
  [4, 12],  // Polegar e m√©dio
  [4, 16],  // Polegar e anelar
  [4, 20],  // Polegar e mindinho
];

// Fun√ß√£o que calcula a dist√¢ncia euclidiana entre dois pontos (p1 e p2)
function getDistance(p1, p2) {
  const dx = p1.x - p2.x; // Diferen√ßa no eixo X
  const dy = p1.y - p2.y; // Diferen√ßa no eixo Y
  return Math.sqrt(dx * dx + dy * dy); // Teorema de Pit√°goras
}

// Fun√ß√£o ass√≠ncrona que ativa a c√¢mera do usu√°rio
async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { width: 640, height: 480 }, // Resolu√ß√£o da c√¢mera
    audio: false // Sem √°udio
  });
  video.srcObject = stream; // Define o v√≠deo como origem do stream
  return new Promise((resolve) => {
    video.onloadedmetadata = () => resolve(video); // Quando o v√≠deo estiver pronto, resolvemos a promise
  });
}

// Fun√ß√£o principal do programa
async function main() {
  // Define o backend do TensorFlow.js como WebGL (para desempenho gr√°fico)
  await tf.setBackend("webgl");

  // Inicia a c√¢mera
  await setupCamera();
  video.play(); // Inicia a reprodu√ß√£o do v√≠deo

  // Define o modelo de detec√ß√£o de m√£os da MediaPipe
  const model = handPoseDetection.SupportedModels.MediaPipeHands;

  // Cria o detector de m√£os com configura√ß√£o leve (lite)
  const detector = await handPoseDetection.createDetector(model, {
    runtime: "mediapipe", // Define o runtime
    modelType: "lite", // Usa o modelo leve (menos pesado)
    solutionPath: "https://cdn.jsdelivr.net/npm/@mediapipe/hands" // URL do pacote do modelo
  });

  // Fun√ß√£o que detecta m√£os continuamente a cada frame
  async function detectHands() {
    const threshold = 10; // Dist√¢ncia m√°xima para considerar dois dedos "encostando"

    // Estima a posi√ß√£o das m√£os no v√≠deo atual
    const hands = await detector.estimateHands(video);

    // Limpa o canvas antes de desenhar novos pontos
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Percorre todas as m√£os detectadas
    for (let hand of hands) {
      const keypoints = hand.keypoints; // Pega os pontos-chave da m√£o

      // Desenha os c√≠rculos coloridos nos pontos das pontas dos dedos
      for (let index of Object.keys(fingertipPoints)) {
        const point = keypoints[index];
        if (point) {
          ctx.beginPath();
          ctx.arc(point.x, point.y, 8, 0, 2 * Math.PI); // Desenha um c√≠rculo no ponto
          ctx.fillStyle = fingertipPoints[index]; // Cor do dedo
          ctx.fill(); // Preenche o c√≠rculo
        }
      }

      // Vari√°veis para armazenar o estado dos gestos
      let pegarDetectado = false;
      let soltarDetectado = false;

      // Verifica cada par de pontos (polegar com os outros dedos)
      for (let [a, b] of proximityPairs) {
        const p1 = keypoints[a];
        const p2 = keypoints[b];
        if (p1 && p2) {
          const d = getDistance(p1, p2); // Calcula a dist√¢ncia entre os dois pontos
          if (d < threshold) pegarDetectado = true; // Se estiverem muito pr√≥ximos, √© um gesto de "pegar"
          if (d > threshold * 10) soltarDetectado = true; // Se estiverem muito longe, √© um gesto de "soltar"
        }
      }

      // Determina qual gesto foi detectado com base nos pares
      if (pegarDetectado && !soltarDetectado) {
        console.log("üñêÔ∏è Gesto final: pegar");
      } else if (soltarDetectado && !pegarDetectado) {
        console.log("üôå Gesto final: soltar");
      }
    }

    // Chama a detec√ß√£o novamente no pr√≥ximo frame (loop cont√≠nuo)
    requestAnimationFrame(detectHands);
  }

  // Inicia o processo de detec√ß√£o
  detectHands();
}

// Chama a fun√ß√£o principal para come√ßar o programa
main();
